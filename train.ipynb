{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-05 YOLOv7\n",
    "\n",
    "Please run the code with \"VScode-devcontainer\".\n",
    "\n",
    "> You can find the tutorial provided by Visual Studio Code here :   \n",
    "> [https://code.visualstudio.com/docs/devcontainers/containers](https://code.visualstudio.com/docs/devcontainers/containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "from torch.cuda import amp\n",
    "from tqdm import tqdm\n",
    "\n",
    "import test  # import test.py to get mAP after each epoch\n",
    "from models.yolo import Model\n",
    "from utils.autoanchor import check_anchors\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import labels_to_class_weights, increment_path, init_seeds, fitness, check_dataset, check_file, check_img_size, one_cycle, colorstr\n",
    "from utils.loss import ComputeLoss, ComputeLossOTA\n",
    "from utils.torch_utils import ModelEMA, intersect_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER_NAME = \"SGD\"\n",
    "BATCH_SIZE = 4\n",
    "EPOCH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_divisible(x, divisor):\n",
    "#     # Returns x evenly divisible by divisor\n",
    "#     return math.ceil(x / divisor) * divisor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for fine-tune\n",
    "\n",
    "- Dataset : Aquarium Dataset\n",
    "    - [https://public.roboflow.com/object-detection/aquarium](https://public.roboflow.com/object-detection/aquarium)\n",
    "\n",
    "---\n",
    "\n",
    "- Dataloader\n",
    "    - [pin_memory](https://pytorch.org/docs/stable/data.html#memory-pinning)\n",
    "    - [Train Custom Data (From YOLOv5)](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)\n",
    "\n",
    "---\n",
    "\n",
    "wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataloader(path, imgsz, batch_size, stride, opt, hyp=None, augment=False, cache=False, pad=0.0, rect=False, rank=-1, world_size=1, workers=8, image_weights=False, quad=False, prefix=\"\"):\n",
    "\n",
    "#     dataset = LoadImagesAndLabels(path, imgsz, batch_size, augment=augment, hyp=hyp, rect=rect, cache_images=cache, single_cls=opt.single_cls, stride=int(stride), pad=pad, image_weights=image_weights, prefix=prefix)  # augment images  # augmentation hyperparameters  # rectangular training\n",
    "\n",
    "#     batch_size = min(batch_size, len(dataset))\n",
    "#     nw = min([os.cpu_count() // world_size, batch_size if batch_size > 1 else 0, workers])  # number of workers\n",
    "#     sampler = torch.utils.data.distributed.DistributedSampler(dataset) if rank != -1 else None\n",
    "#     loader = torch.utils.data.DataLoader if image_weights else InfiniteDataLoader\n",
    "#     # Use torch.utils.data.DataLoader() if dataset.properties will update during training else InfiniteDataLoader()\n",
    "#     dataloader = loader(dataset, batch_size=batch_size, num_workers=nw, sampler=sampler, pin_memory=True, collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn)\n",
    "#     return dataloader\n",
    "\n",
    "\n",
    "# # Trainloader\n",
    "# dataloader = create_dataloader(path=data_dict[\"train\"], imgsz=imgsz, batch_size=BATCH_SIZE, stride=32, opt=opt, hyp=hyp, augment=True, prefix=colorstr(\"train: \"))\n",
    "# testloader = create_dataloader(path=data_dict[\"val\"], imgsz=imgsz_test, batch_size=BATCH_SIZE * 2, stride=32, opt=opt, hyp=hyp, rect=True, pad=0.5, prefix=colorstr(\"val: \"))[0]  # testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download pre-trained weight\n",
    "\n",
    "Attempt to download the file if it does not exist.  \n",
    "\n",
    "- Reference  \n",
    "    - [https://github.com/WongKinYiu/yolov7/releases/tag/v0.1](https://github.com/WongKinYiu/yolov7/releases/tag/v0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt_download(filename):\n",
    "    file = Path(filename)\n",
    "\n",
    "    # download if not found locally\n",
    "    if not file.exists():\n",
    "        repo = \"WongKinYiu/yolov7\"\n",
    "        tag = \"v0.1\"\n",
    "        name = file.name\n",
    "        url = f\"https://github.com/{repo}/releases/download/{tag}/{name}\"\n",
    "        print(f\"Downloading {url} to {file}...\")\n",
    "        torch.hub.download_url_to_file(url, file)\n",
    "\n",
    "attempt_download(filename=\"yolov7_training.pt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hyp, opt, device):\n",
    "    print(colorstr(\"hyperparameters: \") + \", \".join(f\"{k}={v}\" for k, v in hyp.items()))\n",
    "    save_dir, epochs, batch_size, weights = Path(opt.save_dir), opt.epochs, opt.batch_size, opt.weights\n",
    "\n",
    "    # Directories\n",
    "    wdir = save_dir / \"weights\"\n",
    "    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n",
    "    best = wdir / \"best.pt\"\n",
    "    results_file = save_dir / \"results.txt\"\n",
    "\n",
    "    # Save run settings\n",
    "    with open(save_dir / \"hyp.yaml\", \"w\") as f:\n",
    "        yaml.dump(hyp, f, sort_keys=False)\n",
    "    with open(save_dir / \"opt.yaml\", \"w\") as f:\n",
    "        yaml.dump(vars(opt), f, sort_keys=False)\n",
    "\n",
    "    # Configure\n",
    "    plots = True  # create plots\n",
    "    cuda = device.type != \"cpu\"\n",
    "    init_seeds(1)\n",
    "    with open(opt.data) as f:\n",
    "        data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n",
    "\n",
    "    # Logging- Doing this before checking the dataset. Might update data_dict\n",
    "    opt.hyp = hyp  # add hyperparameters\n",
    "\n",
    "    nc = int(data_dict[\"nc\"])  # number of classes\n",
    "    names = data_dict[\"names\"]  # class names\n",
    "\n",
    "    # Model\n",
    "    attempt_download(weights)  # download if not found locally\n",
    "    ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
    "    model = Model(opt.cfg or ckpt[\"model\"].yaml, ch=3, nc=nc, anchors=hyp.get(\"anchors\")).to(device)  # create\n",
    "    state_dict = ckpt[\"model\"].float().state_dict()  # to FP32\n",
    "    state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=[\"anchor\"])  # intersect\n",
    "    model.load_state_dict(state_dict, strict=False)  # load\n",
    "    print(\"Transferred %g/%g items from %s\" % (len(state_dict), len(model.state_dict()), weights))  # report\n",
    "\n",
    "    check_dataset(data_dict)  # check\n",
    "\n",
    "    # Freeze\n",
    "    freeze = [f\"model.{x}.\" for x in range(0)]  # parameter names to freeze (full or partial)\n",
    "    for k, v in model.named_parameters():\n",
    "        v.requires_grad = True  # train all layers\n",
    "        if any(x in k for x in freeze):\n",
    "            print(\"freezing %s\" % k)\n",
    "            v.requires_grad = False\n",
    "\n",
    "    # Optimizer\n",
    "    nbs = 64  # nominal batch size\n",
    "    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing\n",
    "    hyp[\"weight_decay\"] *= batch_size * accumulate / nbs  # scale weight_decay\n",
    "    print(f\"Scaled weight_decay = {hyp['weight_decay']}\")\n",
    "\n",
    "    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n",
    "    for k, v in model.named_modules():\n",
    "        if hasattr(v, \"bias\") and isinstance(v.bias, nn.Parameter):\n",
    "            pg2.append(v.bias)  # biases\n",
    "        if isinstance(v, nn.BatchNorm2d):\n",
    "            pg0.append(v.weight)  # no decay\n",
    "        elif hasattr(v, \"weight\") and isinstance(v.weight, nn.Parameter):\n",
    "            pg1.append(v.weight)  # apply decay\n",
    "        if hasattr(v, \"im\"):\n",
    "            if hasattr(v.im, \"implicit\"):\n",
    "                pg0.append(v.im.implicit)\n",
    "            else:\n",
    "                for iv in v.im:\n",
    "                    pg0.append(iv.implicit)\n",
    "        if hasattr(v, \"imc\"):\n",
    "            if hasattr(v.imc, \"implicit\"):\n",
    "                pg0.append(v.imc.implicit)\n",
    "            else:\n",
    "                for iv in v.imc:\n",
    "                    pg0.append(iv.implicit)\n",
    "        if hasattr(v, \"imb\"):\n",
    "            if hasattr(v.imb, \"implicit\"):\n",
    "                pg0.append(v.imb.implicit)\n",
    "            else:\n",
    "                for iv in v.imb:\n",
    "                    pg0.append(iv.implicit)\n",
    "        if hasattr(v, \"imo\"):\n",
    "            if hasattr(v.imo, \"implicit\"):\n",
    "                pg0.append(v.imo.implicit)\n",
    "            else:\n",
    "                for iv in v.imo:\n",
    "                    pg0.append(iv.implicit)\n",
    "        if hasattr(v, \"ia\"):\n",
    "            if hasattr(v.ia, \"implicit\"):\n",
    "                pg0.append(v.ia.implicit)\n",
    "            else:\n",
    "                for iv in v.ia:\n",
    "                    pg0.append(iv.implicit)\n",
    "        if hasattr(v, \"attn\"):\n",
    "            if hasattr(v.attn, \"logit_scale\"):\n",
    "                pg0.append(v.attn.logit_scale)\n",
    "            if hasattr(v.attn, \"q_bias\"):\n",
    "                pg0.append(v.attn.q_bias)\n",
    "            if hasattr(v.attn, \"v_bias\"):\n",
    "                pg0.append(v.attn.v_bias)\n",
    "            if hasattr(v.attn, \"relative_position_bias_table\"):\n",
    "                pg0.append(v.attn.relative_position_bias_table)\n",
    "        if hasattr(v, \"rbr_dense\"):\n",
    "            if hasattr(v.rbr_dense, \"weight_rbr_origin\"):\n",
    "                pg0.append(v.rbr_dense.weight_rbr_origin)\n",
    "            if hasattr(v.rbr_dense, \"weight_rbr_avg_conv\"):\n",
    "                pg0.append(v.rbr_dense.weight_rbr_avg_conv)\n",
    "            if hasattr(v.rbr_dense, \"weight_rbr_pfir_conv\"):\n",
    "                pg0.append(v.rbr_dense.weight_rbr_pfir_conv)\n",
    "            if hasattr(v.rbr_dense, \"weight_rbr_1x1_kxk_idconv1\"):\n",
    "                pg0.append(v.rbr_dense.weight_rbr_1x1_kxk_idconv1)\n",
    "            if hasattr(v.rbr_dense, \"weight_rbr_1x1_kxk_conv2\"):\n",
    "                pg0.append(v.rbr_dense.weight_rbr_1x1_kxk_conv2)\n",
    "            if hasattr(v.rbr_dense, \"weight_rbr_gconv_dw\"):\n",
    "                pg0.append(v.rbr_dense.weight_rbr_gconv_dw)\n",
    "            if hasattr(v.rbr_dense, \"weight_rbr_gconv_pw\"):\n",
    "                pg0.append(v.rbr_dense.weight_rbr_gconv_pw)\n",
    "            if hasattr(v.rbr_dense, \"vector\"):\n",
    "                pg0.append(v.rbr_dense.vector)\n",
    "\n",
    "    if OPTIMIZER_NAME == \"Adam\":\n",
    "        optimizer = optim.Adam(pg0, lr=hyp[\"lr0\"], betas=(hyp[\"momentum\"], 0.999))  # adjust beta1 to momentum\n",
    "    elif OPTIMIZER_NAME == \"SGD\":\n",
    "        optimizer = optim.SGD(pg0, lr=hyp[\"lr0\"], momentum=hyp[\"momentum\"], nesterov=True)\n",
    "\n",
    "    optimizer.add_param_group({\"params\": pg1, \"weight_decay\": hyp[\"weight_decay\"]})  # add pg1 with weight_decay\n",
    "    optimizer.add_param_group({\"params\": pg2})  # add pg2 (biases)\n",
    "    print(\"Optimizer groups: %g .bias, %g conv.weight, %g other\" % (len(pg2), len(pg1), len(pg0)))\n",
    "    del pg0, pg1, pg2\n",
    "\n",
    "    lf = one_cycle(1, hyp[\"lrf\"], epochs)  # cosine 1->hyp['lrf']\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "\n",
    "    # EMA\n",
    "    ema = ModelEMA(model)\n",
    "\n",
    "    # Resume\n",
    "    start_epoch, best_fitness = 0, 0.0\n",
    "\n",
    "    # Optimizer\n",
    "    if ckpt[\"optimizer\"] is not None:\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        best_fitness = ckpt[\"best_fitness\"]\n",
    "\n",
    "    # EMA\n",
    "    if ckpt.get(\"ema\"):\n",
    "        ema.ema.load_state_dict(ckpt[\"ema\"].float().state_dict())\n",
    "        ema.updates = ckpt[\"updates\"]\n",
    "\n",
    "    # Results\n",
    "    if ckpt.get(\"training_results\") is not None:\n",
    "        results_file.write_text(ckpt[\"training_results\"])  # write results.txt\n",
    "\n",
    "    # Epochs\n",
    "    start_epoch = ckpt[\"epoch\"] + 1\n",
    "    if epochs < start_epoch:\n",
    "        print(\"%s has been trained for %g epochs. Fine-tuning for %g additional epochs.\" % (weights, ckpt[\"epoch\"], epochs))\n",
    "        epochs += ckpt[\"epoch\"]  # finetune additional epochs\n",
    "    del ckpt, state_dict\n",
    "\n",
    "    # Image sizes\n",
    "    nl = model.model[-1].nl  # number of detection layers (used for scaling hyp['obj'])\n",
    "    imgsz, imgsz_test = [check_img_size(x, 32) for x in opt.img_size]  # verify imgsz are gs-multiples\n",
    "\n",
    "    # Trainloader\n",
    "    dataloader, dataset = create_dataloader(path=data_dict[\"train\"], imgsz=imgsz, batch_size=batch_size, stride=32, opt=opt, hyp=hyp, augment=True, prefix=colorstr(\"train: \"))\n",
    "    testloader = create_dataloader(path=data_dict[\"val\"], imgsz=imgsz_test, batch_size=batch_size * 2, stride=32, opt=opt, hyp=hyp, rect=True, pad=0.5, prefix=colorstr(\"val: \"))[0]  # testloader\n",
    "    nb = len(dataloader)  # number of batches\n",
    "\n",
    "    labels = np.concatenate(dataset.labels, 0)\n",
    "    c = torch.tensor(labels[:, 0])  # classes\n",
    "\n",
    "    # Anchors\n",
    "    if not opt.noautoanchor:\n",
    "        check_anchors(dataset, model=model, thr=hyp[\"anchor_t\"], imgsz=imgsz)\n",
    "    model.half().float()  # pre-reduce anchor precision\n",
    "\n",
    "    # Model parameters\n",
    "    hyp[\"box\"] *= 3.0 / nl  # scale to layers\n",
    "    hyp[\"cls\"] *= nc / 80.0 * 3.0 / nl  # scale to classes and layers\n",
    "    hyp[\"obj\"] *= (imgsz / 640) ** 2 * 3.0 / nl  # scale to image size and layers\n",
    "    hyp[\"label_smoothing\"] = 0.0\n",
    "    model.nc = nc  # attach number of classes to model\n",
    "    model.hyp = hyp  # attach hyperparameters to model\n",
    "    model.gr = 1.0  # iou loss ratio (obj_loss = 1.0 or iou)\n",
    "    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  # attach class weights\n",
    "    model.names = names\n",
    "\n",
    "    # Start training\n",
    "    nw = max(round(hyp[\"warmup_epochs\"] * nb), 1000)  # number of warmup iterations, max(3 epochs, 1k iterations)\n",
    "    results = (0, 0, 0, 0, 0, 0, 0)  # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)\n",
    "    scheduler.last_epoch = start_epoch - 1  # do not move\n",
    "    scaler = amp.GradScaler(enabled=cuda)\n",
    "    compute_loss_ota = ComputeLossOTA(model)  # init loss class\n",
    "    compute_loss = ComputeLoss(model)  # init loss class\n",
    "    print(f\"Image sizes {imgsz} train, {imgsz_test} test\\n\" f\"Using {dataloader.num_workers} dataloader workers\\n\" f\"Logging results to {save_dir}\\n\" f\"Starting training for {epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "\n",
    "        mloss = torch.zeros(4, device=device)  # mean losses\n",
    "        print((\"\\n\" + \"%10s\" * 8) % (\"Epoch\", \"gpu_mem\", \"box\", \"obj\", \"cls\", \"total\", \"labels\", \"img_size\"))\n",
    "        pbar = tqdm(enumerate(dataloader), total=nb)  # progress bar\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # batch -------------------------------------------------------------\n",
    "        for i, (imgs, targets, paths, _) in pbar:\n",
    "            ni = i + nb * epoch  # number integrated batches (since train start)\n",
    "            imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
    "\n",
    "            # Warmup\n",
    "            if ni <= nw:\n",
    "                xi = [0, nw]  # x interp\n",
    "                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
    "                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n",
    "                for j, x in enumerate(optimizer.param_groups):\n",
    "                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
    "                    x[\"lr\"] = np.interp(ni, xi, [hyp[\"warmup_bias_lr\"] if j == 2 else 0.0, x[\"initial_lr\"] * lf(epoch)])\n",
    "                    if \"momentum\" in x:\n",
    "                        x[\"momentum\"] = np.interp(ni, xi, [hyp[\"warmup_momentum\"], hyp[\"momentum\"]])\n",
    "\n",
    "            # Forward\n",
    "            with amp.autocast(enabled=cuda):\n",
    "                pred = model(imgs)  # forward\n",
    "                if \"loss_ota\" not in hyp or hyp[\"loss_ota\"] == 1:\n",
    "                    loss, loss_items = compute_loss_ota(pred, targets.to(device), imgs)  # loss scaled by batch_size\n",
    "                else:\n",
    "                    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
    "\n",
    "            # Backward\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Optimize\n",
    "            if ni % accumulate == 0:\n",
    "                scaler.step(optimizer)  # optimizer.step\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                if ema:\n",
    "                    ema.update(model)\n",
    "\n",
    "            # Print\n",
    "            mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
    "            mem = \"%.3gG\" % (torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0)  # (GB)\n",
    "            s = (\"%10s\" * 2 + \"%10.4g\" * 6) % (\"%g/%g\" % (epoch, epochs - 1), mem, *mloss, targets.shape[0], imgs.shape[-1])\n",
    "            pbar.set_description(s)\n",
    "\n",
    "        # Scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # mAP\n",
    "        ema.update_attr(model, include=[\"yaml\", \"nc\", \"hyp\", \"gr\", \"names\", \"stride\", \"class_weights\"])\n",
    "        final_epoch = epoch + 1 == epochs\n",
    "        results, maps, times = test.test(data_dict, batch_size=batch_size * 2, imgsz=imgsz_test, model=ema.ema, dataloader=testloader, save_dir=save_dir, verbose=nc < 50 and final_epoch, plots=plots and final_epoch, compute_loss=compute_loss)\n",
    "\n",
    "        # Write\n",
    "        with open(results_file, \"a\") as f:\n",
    "            f.write(s + \"%10.4g\" * 7 % results + \"\\n\")  # append metrics, val_loss\n",
    "\n",
    "        # Update best mAP\n",
    "        fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]\n",
    "        if fi > best_fitness:\n",
    "            best_fitness = fi\n",
    "\n",
    "        # Save model\n",
    "        if final_epoch:  # if save\n",
    "            ckpt = {\"epoch\": epoch, \"best_fitness\": best_fitness, \"training_results\": results_file.read_text(), \"model\": deepcopy(model).half(), \"ema\": deepcopy(ema.ema).half(), \"updates\": ema.updates, \"optimizer\": optimizer.state_dict(), \"wandb_id\": None}\n",
    "            torch.save(ckpt, best)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(weights='yolov7_training.pt', noautoanchor=False, single_cls=False, batch_size=4, epochs=2, data='data/AquariumDataset/data.yaml', cfg='cfg/training/yolov7.yaml', hyp='data/hyp.scratch.custom.yaml', img_size=[640, 640], save_dir='runs/train/yolov7-custom2')\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 555/566 items from yolov7_training.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'data/AquariumDataset/train/labels.cache' images and labels... 448 found, 0 missing, 1 empty, 0 corrupted: 100%|██████████| 448/448 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/AquariumDataset/valid/labels.cache' images and labels... 127 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 127/127 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.03, Best Possible Recall (BPR) = 0.9991\n",
      "Image sizes 640 train, 640 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/yolov7-custom2\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0/1      3.4G   0.07729   0.02407   0.03187    0.1332        29       640: 100%|██████████| 112/112 [00:14<00:00,  7.85it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 16/16 [00:01<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         127         909     0.00797      0.0417     0.00152    0.000292\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/1      4.6G   0.06619   0.02692   0.02818    0.1213        56       640: 100%|██████████| 112/112 [00:13<00:00,  8.10it/s]\n",
      "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 16/16 [00:01<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 all         127         909      0.0374       0.194      0.0214     0.00574\n",
      "                fish         127         459      0.0551       0.458      0.0797      0.0184\n",
      "           jellyfish         127         155      0.0441       0.161      0.0158     0.00344\n",
      "             penguin         127         104       0.042      0.0769     0.00785     0.00175\n",
      "              puffin         127          74      0.0387       0.108     0.00575     0.00173\n",
      "               shark         127          57      0.0112      0.0702     0.00539     0.00156\n",
      "            starfish         127          27       0.051       0.333      0.0251     0.00979\n",
      "            stingray         127          33      0.0196       0.152     0.00987     0.00351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03737289769822971,\n",
       " 0.1941231101322982,\n",
       " 0.021350714084934944,\n",
       " 0.005740058229584408,\n",
       " 0.09389394521713257,\n",
       " 0.04816664382815361,\n",
       " 0.03097183257341385)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Namespace()\n",
    "\n",
    "opt.weights = \"yolov7_training.pt\"\n",
    "opt.noautoanchor = False\n",
    "opt.single_cls = False\n",
    "\n",
    "opt.batch_size = BATCH_SIZE\n",
    "opt.epochs = EPOCH\n",
    "\n",
    "opt.data, opt.cfg, opt.hyp = check_file(\"data/AquariumDataset/data.yaml\"), check_file(\"cfg/training/yolov7.yaml\"), check_file(\"data/hyp.scratch.custom.yaml\")  # check files\n",
    "opt.img_size = [640, 640]\n",
    "opt.save_dir = increment_path(Path(\"runs/train\") / \"yolov7-custom\", exist_ok=False)  # increment run\n",
    "\n",
    "# Hyperparameters\n",
    "with open(opt.hyp) as f:\n",
    "    hyp = yaml.load(f, Loader=yaml.SafeLoader)  # load hyps\n",
    "\n",
    "# Train\n",
    "print(opt)\n",
    "train(hyp, opt, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
