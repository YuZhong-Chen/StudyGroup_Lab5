{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-05 YOLOv7 Inference\n",
    "\n",
    "Please run the code with \"VScode-devcontainer\".\n",
    "\n",
    "> You can find the tutorial provided by Visual Studio Code here :   \n",
    "> [https://code.visualstudio.com/docs/devcontainers/containers](https://code.visualstudio.com/docs/devcontainers/containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadImages\n",
    "from utils.general import non_max_suppression, scale_coords, increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import time_synchronized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Detect Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(weights, source, conf, iou_thres):\n",
    "    # Directories\n",
    "    save_dir = Path(increment_path(Path(\"runs/detect\") / \"exp\", exist_ok=False))  # increment run\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "\n",
    "    # half precision only supported on CUDA\n",
    "    if device.type != \"cpu\":\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Set Dataloader\n",
    "    dataset = LoadImages(source, img_size=640, stride=32)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "\n",
    "    # Run inference\n",
    "    if device.type != \"cpu\":\n",
    "        model(torch.zeros(1, 3, 640, 640).to(device).type_as(next(model.parameters())))  # run once\n",
    "    old_img_w = old_img_h = 640\n",
    "    old_img_b = 1\n",
    "\n",
    "    for path, img, im0s, _ in dataset:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if device.type != \"cpu\" else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Warmup\n",
    "        if device.type != \"cpu\" and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
    "            old_img_b = img.shape[0]\n",
    "            old_img_h = img.shape[2]\n",
    "            old_img_w = img.shape[3]\n",
    "            for i in range(3):\n",
    "                model(img)[0]\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        with torch.no_grad():  # Calculating gradients would cause a GPU memory leak\n",
    "            pred = model(img)[0]\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, conf, iou_thres)\n",
    "        t3 = time_synchronized()\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            s, im0 = \"\", im0s\n",
    "            p = Path(path)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # img.jpg\n",
    "\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    label = f\"{names[int(cls)]} {conf:.2f}\"\n",
    "                    plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
    "\n",
    "            # Print time (inference + NMS)\n",
    "            print(f\"{s}\\nDone. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS\")\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if dataset.mode == \"image\":\n",
    "                cv2.imwrite(save_path, im0)\n",
    "                print(f\"The image with the result is saved in: {save_path}\")\n",
    "\n",
    "            # Change backend\n",
    "            matplotlib.use(\"TkAgg\")\n",
    "            \n",
    "            # Show Image\n",
    "            plt.figure()\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(cv2.cvtColor(im0, cv2.COLOR_BGR2RGB))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "3 persons, 8 sheeps, 1 cell phone, \n",
      "Done. (6.6ms) Inference, (0.8ms) NMS\n",
      "The image with the result is saved in: runs/detect/exp33/test2.jpg\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    detect(weights=\"yolov7.pt\", source=\"inference/images/test2.jpg\", conf=0.5, iou_thres=0.45)\n",
    "    # detect(weights=\"runs/train/yolov7-custom13/weights/weight.pt\", source=\"inference/images/fish1.jpg\", conf=0.5, iou_thres=0.45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
